{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3680aaba-6702-4854-aee9-66468e2f6027",
   "metadata": {},
   "source": [
    "## This notebook is used to run hyperparameter optimization studies with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f10e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmenear/Projects/eagle-jobs/environment/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import joblib\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from eagle_jobs.operation_support import train_test_split\n",
    "from eagle_jobs.data_preprocessing import label_encode_columns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcb79a4-f0e1-4593-ad00-c3d31c8c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs():\n",
    "    # Import pkl file\n",
    "    filepath = os.path.join('../data/', 'eagle_data.parquet')\n",
    "    eagle_df = pd.read_parquet(filepath)\n",
    "    \n",
    "    categorical_features = ['user','partition']\n",
    "    label_encode_columns(eagle_df, categorical_features)\n",
    "    \n",
    "    start_time = eagle_df.submit_time.min()\n",
    "    end_time = eagle_df.submit_time.max()\n",
    "    split_times = pd.date_range(start_time, end_time, periods=22)[1:21]\n",
    "    \n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    for split_time in split_times:\n",
    "        train_df, test_df = train_test_split(eagle_df, split_time, training_window=100, testing_window=1)\n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "    \n",
    "    return train_dfs, test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2dcb1c7-f2c6-4b56-97ad-d27dc4aaee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, test_dfs = get_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc69ea0-f774-4adf-b5af-d31c8aa11733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(i, train_dfs, test_dfs):\n",
    "    features = ['wallclock_req','processors_req','mem_req','nodes_req','gpus_req','user','partition']\n",
    "    target = 'run_time'\n",
    "    X_train = train_dfs[i][features]\n",
    "    y_train = train_dfs[i][target]\n",
    "    X_test = test_dfs[i][features]\n",
    "    y_test = test_dfs[i][target]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4974459-d3d2-48e2-8a29-cb2a0c2f30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to fit and evaluate a model with given hyperparameters on a single dataset \n",
    "def fit_model(params):\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    rmse_list = list()\n",
    "    eval_name = 'val'\n",
    "    for i in range(len(train_dfs)):\n",
    "        X_train, y_train, X_test, y_test = load_data(i, train_dfs, test_dfs)\n",
    "        model = XGBRegressor(**params) \n",
    "        model.fit(X_train, y_train) \n",
    "        y_pred = model.predict(X_test) \n",
    "        y_pred = model.predict(X_test) \n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "        rmse_list.append(rmse)\n",
    "    rmse_avg = sum(rmse_list)/len(rmse_list) / 3600\n",
    "    return sum(rmse_list)/len(rmse_list) / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb47e5-ca40-431b-bd96-2642516a7de7",
   "metadata": {},
   "source": [
    "### Define the objective function.\n",
    "See https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/001_first.html#sphx-glr-tutorial-10-key-features-001-first-py for an introduction to using Optuna for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812da308-69c3-4ea3-be83-969443cf65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Save the study before running the next trial\n",
    "    joblib.dump(study, \"../results/optuna_studies/study_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H\") + \".pkl\")\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 0.5)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0, 1)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1)\n",
    "    random_state = 42\n",
    "    \n",
    "    params = {'learning_rate': learning_rate, 'subsample': subsample, 'colsample_bytree': colsample_bytree, \\\n",
    "                  'gamma': gamma, 'max_depth': max_depth, 'n_estimators': n_estimators, 'random_state': random_state}\n",
    "    result = fit_model(params)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73b8c2-feb7-4d08-8b5c-3df9b75cdb48",
   "metadata": {},
   "source": [
    "### If continuing a previous study, set `load_study` to `True` and provide the study name.\n",
    "*Note:* Studies are saved in the `studies` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8003a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_study = True\n",
    "study_name = \"study.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21568a5e-8f94-4035-94c3-77098e4e67a7",
   "metadata": {},
   "source": [
    "### Either load the previous study or create a new study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ff5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial until now:\n",
      " Value:  10.062161645354056\n",
      " Params: \n",
      "    n_estimators: 149\n",
      "    max_depth: 6\n",
      "    learning_rate: 0.2727776229229609\n",
      "    gamma: 0.020592249476861557\n",
      "    subsample: 0.9072211939661046\n",
      "    colsample_bytree: 0.7581516666988656\n"
     ]
    }
   ],
   "source": [
    "if load_study:\n",
    "    study = joblib.load(\"../results/optuna_studies/\" + study_name)\n",
    "    print(\"Best trial until now:\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f6ac9-735c-49ad-abd7-444cab0829e6",
   "metadata": {},
   "source": [
    "### Run the study.\n",
    "(Increase `n_trials` to achieve better hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daa16b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 22:34:39,919]\u001b[0m Trial 2 finished with value: 10.693527701830137 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.46500367062942416, 'gamma': 0.7971318540434682, 'subsample': 0.685912161746016, 'colsample_bytree': 0.7608341747243939}. Best is trial 0 with value: 10.062161645354056.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 22:36:32,644]\u001b[0m Trial 3 finished with value: 10.128774109507294 and parameters: {'n_estimators': 110, 'max_depth': 3, 'learning_rate': 0.24514684699626466, 'gamma': 0.855343913396993, 'subsample': 0.8394807982777521, 'colsample_bytree': 0.895700308265232}. Best is trial 0 with value: 10.062161645354056.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb4db7-3339-4ba3-bbdb-e4c0104174b9",
   "metadata": {},
   "source": [
    "### Print the hyperparameter and objective function values for the best trial in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5efd2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.2727776229229609, 'gamma': 0.020592249476861557, 'subsample': 0.9072211939661046, 'colsample_bytree': 0.7581516666988656}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf2e753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.062161645354056\n"
     ]
    }
   ],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbf872-7a4a-4847-bb00-51034c43dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
